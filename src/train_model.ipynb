{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LulJH1nh43MP"
      },
      "source": [
        "# Part 1: Imports + Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SFGSIA_D4pQ3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import time\n",
        "import h5py\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define label hot encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "LABEL_ENCODING = {\n",
        "    0: 'angry',\n",
        "    1: 'disgust',\n",
        "    2: 'fear',\n",
        "    3: 'happy',\n",
        "    4: 'sad',\n",
        "    5: 'surprised',\n",
        "    6: 'natural',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCqBvkPN5W6E"
      },
      "source": [
        "# Part 2: Defining the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sDrVT2RF5aBX"
      },
      "outputs": [],
      "source": [
        "class EmojifyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmojifyNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 4, 3, stride=1, padding=1)\n",
        "        self.mxpl1 = nn.MaxPool2d(3, 2)\n",
        "        self.conv2 = nn.Conv2d(4, 16, 3, stride=1, padding=1)\n",
        "        self.mxpl2 = nn.MaxPool2d(3, 2)\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
        "        self.mxpl3 = nn.MaxPool2d(3, 2)\n",
        "        self.conv4 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
        "        self.mxpl4 = nn.MaxPool2d(3, 2)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
        "        self.mxpl5 = nn.MaxPool2d(3, 2)\n",
        "        self.fc1 = nn.Linear(576, 7)\n",
        "        self.accuracy = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        X = self.mxpl1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.mxpl2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.mxpl3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.mxpl4(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, prediction, label, reduction='mean'):\n",
        "        loss_val = F.cross_entropy(prediction, label.squeeze(), reduction=reduction)\n",
        "        return loss_val\n",
        "\n",
        "    def save_model(self, file_path):\n",
        "        torch.save(self.state_dict(), file_path)\n",
        "\n",
        "    def load_model(self, file_path):\n",
        "        self.load_state_dict(torch.load(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tknYM0KO5-03"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for batch_idx, (data, label) in enumerate(train_loader):\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = model.loss(output, label)\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                time.ctime(time.time()),\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    return np.mean(losses)\n",
        "\n",
        "def test(model, device, test_loader, log_interval=None):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, label) in enumerate(test_loader):\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data)\n",
        "            test_loss_on = model.loss(output, label, reduction='sum').item()\n",
        "            test_loss += test_loss_on\n",
        "            pred = output.max(1)[1]\n",
        "            correct_mask = pred.eq(label.view_as(pred))\n",
        "            num_correct = correct_mask.sum().item()\n",
        "            correct += num_correct\n",
        "            if log_interval is not None and batch_idx % log_interval == 0:\n",
        "                print('{} Test: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    time.ctime(time.time()),\n",
        "                    batch_idx * len(data), len(test_loader.dataset),\n",
        "                    100. * batch_idx / len(test_loader), test_loss_on))\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset), test_accuracy))\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4ZuYFZ6Hd5"
      },
      "source": [
        "# Part 3: Loading Data + Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Il3MwuAr6Gkl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x000002473AA50320>>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1203, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"C:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1174, in _shutdown_workers\n",
            "    if self._persistent_workers or self._workers_status[worker_id]:\n",
            "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Examples: 28709\n",
            "Testing Examples: 7178\n",
            "\n",
            "Looking at example 12345 with label 'happy':\n",
            "torch.Size([1, 48, 48])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x247168fc4e0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "data_train = datasets.ImageFolder(root=\"../data/train\", transform=transform_train)\n",
        "data_test = datasets.ImageFolder(root=\"../data/test\", transform=transform_test)\n",
        "\n",
        "print(f\"Training Examples: {len(data_train)}\")\n",
        "print(f\"Testing Examples: {len(data_test)}\")  # Dataset said we should have 3589 examples, yet we have x2 - duplicates??\n",
        "\n",
        "indx = 12345\n",
        "example = data_train[indx][0]\n",
        "label   = data_train[indx][1]\n",
        "\n",
        "print(f\"\\nLooking at example {indx} with label '{LABEL_ENCODING[label]}':\")\n",
        "print(example.shape)\n",
        "plt.imshow(np.squeeze(example), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaPaQ_Vz6SxX"
      },
      "source": [
        "# Part 4: Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "c1ENJvt86Scy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cpu\n",
            "num cpus: 12\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (10x1600 and 576x7)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-39-d228862e64cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# pt_util.read_log(LOG_PATH + 'log.pkl', ([], [], []))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-8-77f8085072d4>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, device, test_loader, log_interval)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mtest_loss_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtest_loss_on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-36-cc1146920d8a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x1600 and 576x7)"
          ]
        }
      ],
      "source": [
        "# Play around with these constants, you may find a better setting.\n",
        "BATCH_SIZE = 512\n",
        "TEST_BATCH_SIZE = 10\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 0.2\n",
        "MOMENTUM = 0\n",
        "USE_CUDA = False\n",
        "SEED = 0\n",
        "PRINT_INTERVAL = 100\n",
        "WEIGHT_DECAY = 0\n",
        "\n",
        "# Now the actual training code\n",
        "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "print('num cpus:', multiprocessing.cpu_count())\n",
        "\n",
        "kwargs = {'num_workers': 0,\n",
        "          'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=TEST_BATCH_SIZE,\n",
        "                                          shuffle=True, **kwargs)\n",
        "\n",
        "model = EmojifyNet().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "start_epoch = 0 # model.load_last_model(LOG_PATH)\n",
        "\n",
        "train_losses, test_losses, test_accuracies = [], [], [] # pt_util.read_log(LOG_PATH + 'log.pkl', ([], [], []))\n",
        "test_loss, test_accuracy = test(model, device, test_loader)\n",
        "\n",
        "test_losses.append((start_epoch, test_loss))\n",
        "test_accuracies.append((start_epoch, test_accuracy))\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, EPOCHS + 1):\n",
        "        train_loss = train(model, device, train_loader, optimizer, epoch, PRINT_INTERVAL)\n",
        "        test_loss, test_accuracy = test(model, device, test_loader)\n",
        "        train_losses.append((epoch, train_loss))\n",
        "        test_losses.append((epoch, test_loss))\n",
        "        test_accuracies.append((epoch, test_accuracy))\n",
        "        # pt_util.write_log(LOG_PATH + 'log.pkl', (train_losses, test_losses, test_accuracies))\n",
        "        # model.save_best_model(test_accuracy, LOG_PATH + '%03d.pt' % epoch)\n",
        "\n",
        "\n",
        "except KeyboardInterrupt as ke:\n",
        "    print('Interrupted')\n",
        "except:\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    # model.save_model(LOG_PATH + '%03d.pt' % epoch, 0)\n",
        "    ep, val = zip(*train_losses)\n",
        "    # pt_util.plot(ep, val, 'Train loss', 'Epoch', 'Error')\n",
        "    ep, val = zip(*test_losses)\n",
        "    # pt_util.plot(ep, val, 'Test loss', 'Epoch', 'Error')\n",
        "    ep, val = zip(*test_accuracies)\n",
        "    # pt_util.plot(ep, val, 'Test accuracy', 'Epoch', 'Error')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "train-model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
