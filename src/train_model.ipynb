{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LulJH1nh43MP"
      },
      "source": [
        "# Part 1: Imports + Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SFGSIA_D4pQ3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import time\n",
        "import h5py\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define label hot encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "LABEL_ENCODING = {\n",
        "    0: 'angry',\n",
        "    1: 'disgust',\n",
        "    2: 'fear',\n",
        "    3: 'happy',\n",
        "    4: 'sad',\n",
        "    5: 'surprised',\n",
        "    6: 'natural',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCqBvkPN5W6E"
      },
      "source": [
        "# Part 2: Defining the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "sDrVT2RF5aBX"
      },
      "outputs": [],
      "source": [
        "class EmojifyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmojifyNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
        "\n",
        "        self.mxpl1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
        "\n",
        "        self.mxpl2 = nn.MaxPool2d(3, 3)\n",
        "\n",
        "        self.fc1 = nn.Linear(18432, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        m = 0\n",
        "        v = 1\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.mxpl1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.mxpl2(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        # print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, prediction, label, reduction='mean'):\n",
        "        loss_val = F.cross_entropy(prediction, label.squeeze(), reduction=reduction)\n",
        "        return loss_val\n",
        "\n",
        "    def save_model(self, file_path):\n",
        "        torch.save(self.state_dict(), file_path)\n",
        "\n",
        "    def load_model(self, file_path):\n",
        "        self.load_state_dict(torch.load(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tknYM0KO5-03"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for batch_idx, (data, label) in enumerate(train_loader):\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = model.loss(output, label)\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                time.ctime(time.time()),\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    return np.mean(losses)\n",
        "\n",
        "def test(model, device, test_loader, log_interval=None):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, label) in enumerate(test_loader):\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data)\n",
        "            test_loss_on = model.loss(output, label, reduction='sum').item()\n",
        "            test_loss += test_loss_on\n",
        "            pred = output.max(1)[1]\n",
        "            correct_mask = pred.eq(label.view_as(pred))\n",
        "            num_correct = correct_mask.sum().item()\n",
        "            correct += num_correct\n",
        "            if log_interval is not None and batch_idx % log_interval == 0:\n",
        "                print('{} Test: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    time.ctime(time.time()),\n",
        "                    batch_idx * len(data), len(test_loader.dataset),\n",
        "                    100. * batch_idx / len(test_loader), test_loss_on))\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset), test_accuracy))\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4ZuYFZ6Hd5"
      },
      "source": [
        "# Part 3: Loading Data + Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "Il3MwuAr6Gkl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Examples: 28709\n",
            "Testing Examples: 7178\n",
            "\n",
            "Looking at example 12345 with label 'happy':\n",
            "torch.Size([1, 40, 40])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x20fa39aee48>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAa3ElEQVR4nO2dbYxd1XWG34Ux4HgMeGw8Bo8/AFnICQJXgJUIFKVJqBxUCWiUKlSKaBSJ/KilRMqPWPkTUqkSP/LRH60iOYoVt0qTIiUB1ADFQkFpFEQwCRC7BOwQfw3jO7HBX3zb7P6YM5W5532vz773zswd7/eRrLGX1zl3733OmjPznrXXipQSjDHnPufN9gCMMTODg92YQnCwG1MIDnZjCsHBbkwhONiNKYSegj0iNkbEixGxJyI292tQxpj+E92+Z4+IeQBeAnArgIMAngZwV0rpfzsc09NL/RtuuKGx77vvvkvtx44dq9neeust6nveefXvhRHReAynT5+u2d577z3qO2/evJrtggsuoL6vv/56zfb2229T3/PPP79mGxoaor5sbmy87JwAwO6lU6dOUV+2tuq8zJfZOtnbybnvc655jm8/aL8+rVYLx44do4Pgq9uMDQD2pJReBoCI+DGA2wHIYO+Vp556qrFvq9Wi9p///Oc120svvUR9L7roopptwYIFNRsLagA4efJkzfbGG29QXxaAK1eupL47duyo2V5++WXqu3jx4prtlltuob4XXnhhzca+sSxZsoQez77BHjlyhPqy+Q4PD1PfhQsX1mzsOihf9g1HfdNlwaoCmH2DZrZOdoa6nxhvvvnm+/69adMm6dvLj/ErABw4498HK5sxZgDp5cnOvt3VfjaKiHsA3NPD5xhj+kAvwX4QwJk/Z44CeKXdKaW0BcAWoPff2Y0x3dNLsD8NYG1EXAlgDMBnAfxdX0YlUKLbk08+WbP97ne/o77sd/lLLrmE+jYVnF577TV6PPt9d/ny5dSX/W79yCOPUN8TJ07UbDfddBP1vfrqq2u28fFx6ss0itWrV9dsSndgjI6OUvuiRYtqtg984APUlwmVSsxjMH0g53do9Tt7jhjHNAIlEjKRUWkM7WvWSaDsOthTSqciYhOA/wYwD8DWlNKubs9njJleenmyI6X0MICH+zQWY8w04gw6YwrBwW5MITjYjSmEnn5nn2lUWitTl5liDXAFdf78+dSXpaCy7CalqjIFVaXAsvEyNR/Iyz5jYzt+/Dj1veyyy2o2Nl71VoT5KoWdZeup68CU95xMNWZrmlYLaNWdXd+c7Dd13zB7P9Jw/WQ3phAc7MYUgoPdmEJwsBtTCHNKoFNpqYcOHarZlJjHRKAcoYSJU+3bDDvBhCkAOHz4cM2mUiTZFlO1R31iYqJmU2LPpZdeWrOxualx9Sq6KXoVvZhAp86Zk9ba9Hhlf+edd6gvu3fVGNrXV30+4Ce7McXgYDemEBzsxhSCg92YQnCwG1MIc0qNZ6o7kFdtlaVv5iiozKaUf1YUUaV5shRWlZbK0loVR48erdmUcs8Kc7C5KYWdodY2pwhkToXbphVylRqfUyGXXR9137GqxswG8GumaC8C0unNkJ/sxhSCg92YQnCwG1MIPf3OHhF7AZwAcBrAqZTSjf0YlDGm//RDoPvLlFI913MaOHDgALWzziuKnP3ZTKzJSWVkIpISoXqdg6r4ygQb1dGFCaDsvGpPPhP+WMVagIuXyjen8woTYNkcclJVlQDLUpxV5V52DrWOrPLu0qVLqW97B5xOVXP9Y7wxhdBrsCcAj0XEM1XnF2PMgNLrj/E3p5ReiYhlALZHxB9SSr8808Htn4wZDHp6sqeUXqm+TgD4GSY7u7b7bEkp3WjxzpjZpetgj4iFEbFo6u8A/grAzn4NzBjTX3r5MX4EwM+q9MTzAfxHSunRvoxKoNJlmdrK+nQDPJ1Sqa0sTTKnmANLyVSplyzlV6m1THFWaZpMdVbK/Suv1PpyZqXLMjWeFcQAeG+7iy++mPrmKPfszQi7Dmq92HVQRVOYXd0LbL5qbdg6qnuhXX3vVIW2l15vLwO4vtvjjTEzi1+9GVMIDnZjCsHBbkwhzKn97GqfLxMlVBVXJlgpUYX5MsFKpV6y86r9xsxXpUiydFcmruXCRC+2tkosYkKagq2ZWhuWAqpEQjbeHKFUpU4zmAisBDLmq9aLnUONq93u6rLGGAe7MaXgYDemEBzsxhSCg92YQphTavyRI0eonRWJUGotSxXNSXfN6euWo6oy1ByaviUAeGqtKnDA0jdZ+qlSnJldFfZg10GNi6nW6m0Lu2ZNbQBPo2UptACfW04ar7qX2NjU9W0fr3ozBPjJbkwxONiNKQQHuzGF4GA3phDmlECnhJLh4eHG5+gkYLTDBBSWZqnSR5u2U1K+at95TnsgNjY1XiVataMETXZ9VFoqE7KUuMU+Twl0TAhjwp8SStn9oe4ZJkiqffLsWqr7udVq1Wyqau15573/ed2pSrGf7MYUgoPdmEJwsBtTCA52YwrhrAJdRGwF8NcAJlJK11a2YQD/CWANgL0A/jalxKvy9ZFOxfTaUeJWTn/1ptlyOXujc3qQK2GIiTBKGGLZhTniFPNV65LTwopl67WLTVOwDDolMjJ7r3vnVWYfm6/KGGSZjKpewYkTJ2o2dS+0r02nGGnyZP8BgI1tts0AHk8prQXwePVvY8wAc9Zgrzq8vNpmvh3Aturv2wDc0d9hGWP6Tbfv2UdSSuMAkFIar9o/Udz+yZjBYNqTalJKWwBsAYCI4L/QGGOmnW7V+FZEXA4A1deJ/g3JGDMddPtkfwjA3QDuq74+2LcRdUCptUwBVQo7s6u0xaaptU0rfwLNU1IBrfKzcSlfpk5PTPDvzU3V+LGxMXr88ePHaza1J/9DH/pQzabaPy1atKjxeZkve1Oh7g82X5WayxR9pYbnpHSz6sHr1q2jvpdccsn7/r1r1y553rM+2SPiRwCeBHBNRByMiC9gMshvjYjdAG6t/m2MGWDO+mRPKd0l/usTfR6LMWYacQadMYXgYDemEAZ2P/vnP//5mk21y2GFKFWKI/NlKaUKlQ7JyNnP3nQfNsBFPiUyMjFNCU7LltXTJZi4pdaLHa+EqSuuuKJmU/3KWaqpEujY3Ng6qnuJjUF9FrOzVFeAX3cl7LLzjo6OUt/2eaixAn6yG1MMDnZjCsHBbkwhONiNKQQHuzGFMLBqPKs0mlMZNicFVhVCYL6syIRK42VzUKmmTEVmirVCFWNg6rJS45mSy9bmuuuuo8cz36uuuor6joyM1GxDQ0PUlynnixcvpr7srQZL41Vpy+xNQ3tK6hTs+i5cuJD6sjGoAitMpVdvQNo/T92LgJ/sxhSDg92YQnCwG1MIDnZjCmFgBbqcVEQmpCmBjqVOqsqsTMhiaY85+86VgML2QecIf2vWrKG+TLBSYg8bQ44gycS4lStXUl8mZKlxNU2BVWNjx6tWUzkVjJkgqfbks1RiJRIyu5pv+9zUvAA/2Y0pBge7MYXgYDemEBzsxhRCkxp0WyNiIiJ2nmG7NyLGIuLZ6s9t0ztMY0yvNFHjfwDgXwD8W5v9Oymlb/Z9RBU5vc+YQq5UVXbeHGWXnVd9FlP5lQLLPkup3qyYgyqEwOarxsuUXFatddWqVfR4lgKriimwNVdqPLOrObDzMjVerVdOcRJ2LdUcmt5LagxqXO32nnq9ifZPxpg5Ri+/s2+KiOerH/P5rgRjzMDQbbB/F8DVANYDGAfwLeUYEfdExI6I2NHlZxlj+kBXwZ5SaqWUTqeU3gPwPQAbOvhuSSndmFK6sdtBGmN6p6t02Yi4fKqLK4A7Aezs5N8NTNBQaa1MuFOCBjuvEpHYOZgAokQZJhyqceWcV+2vZrC5qf3sbO87a0Wk9pKztVXzZUKa8mUio6JpJVl1L7FrpmoFsDRpVbW21wrGOfeN4qwjqNo/fQzA0og4CODrAD4WEesBJAB7AXyx8ScaY2aFbts/fX8axmKMmUacQWdMITjYjSkEB7sxhTCwxSuYAqtSTZkiqQpKMHVaqb1N1eWc1FyVAts0zRPgiq8qWsCKRLAUWIAXXmDH5xTgUKo3K0Si1jGn0EXTty2qojA7r7qXXnvttUY2gK+tur45bzVy/PxkN6YQHOzGFIKD3ZhCcLAbUwgDK9AxMU61y+nU8qadHNFMCYJNYWKPEgOZQKd82V7snKqmSqBjIl+OUMrSlg8dOtTYV1WiZUKWGkNTAVaJbuy8Kp2aXd8///nP1Je1f1LXgdUrUDUX2umUWuwnuzGF4GA3phAc7MYUgoPdmEJwsBtTCAOrxucUfmCodMqcc7AxDA0NNf6so0eP1mw5/b1Uqil7e8DGBeSlmjKVn6nmqspvq9Wq2ZQazyrRqvRRNq49e/ZQX6boMyX82LFj9HjmqyrRsrcXSrk/cuRIzabWkV33pum9VuONMQ52Y0rBwW5MITRp/7QyIn4RES9ExK6I+FJlH46I7RGxu/rq2vHGDDBNBLpTAL6SUvptRCwC8ExEbAfw9wAeTyndFxGbAWwG8NV+DUyJIoymaZ4AT0VkogzARTOW4qjGyoQwJcrkVBRlQhYT4gC+R1yNlwlDLEX55MmT9PixsbFGxwO8Qu6rr/LGQ0zo3LmTFzRmQhhbA3UdXn/99UbnBIDh4eGaTd13TEBVYzh8+HDNxu5boC7cdUrxbtL+aTyl9Nvq7ycAvABgBYDbAWyr3LYBuONs5zLGzB5Zv7NHxBoAfwHgKQAjU7Xjq6/1HRfGmIGh8Xv2iBgC8BMAX04pHW9anD4i7gFwT3fDM8b0i0ZP9oiYj8lA/2FK6aeVuRURl1f/fzmACXas2z8ZMxg06QgTmGwK8UJK6dtn/NdDAO4GcF/19cF+DiynsCNDFWBkWXFKgGGiCstkUtlN7LOUYJXTN57NTY2BiXFqLzcbLysMqYQ05staSgF8vGovOMvCUxlwzz33XM22YsWKmk3dS6xg5J/+9Cfqy67l8uXLqS+rN6DuBTYGJtoBdeFOXVug2Y/xNwP4HIDfR8Szle1rmAzy+yPiCwD2A/hMg3MZY2aJJu2ffgVAPVI/0d/hGGOmC2fQGVMIDnZjCsHBbkwhDOx+drZnW6UCMl9VMTZHnWbpjEyxVso/S2vN2Wev9kazuak5MLtK02RzY+mjKr2YvT1QVW9z2kqx86rKrLt27arZWLqtgq3X6Ogo9WVtuNT1VW9LGOwebfoGxPvZjTEOdmNKwcFuTCE42I0phIEV6Fg6Y066rBJl3nzzzZpNCWwMllrLWiwBXGBjoo4aFxPHAL7vXBWnZDAhTn0eE+PYWAGeXqzWlu1nVwUnWcrt4sW8Vgrba8/SeFWqKhuDumZsbk33nQNagGXXUhUUbb9mnWLET3ZjCsHBbkwhONiNKQQHuzGF4GA3phAGVo3fv39/Y19W9EClhDK1VamiLPWQKdk56bZK2WUKrEpLZfYlS5ZQX4ZS43MqyTJYCixT3QGuWqt0WbY26k0FK1TB5qXujxxfluKs1paleqvUWqbyq7cHOfjJbkwhONiNKQQHuzGF0Ev7p3sjYiwinq3+3Db9wzXGdEsv7Z8A4DsppW9Ox8DYHmaVEsqEDiWa5aTGMgGGVf5Ue6tZmqeqZMvErdWrV1NfJnqp+bJUUWYDuPDH0jzV/m41Xsa+fftqNlVdlq25Eg6vuOKKmo2l96rjmZCm9ogzuxIZlcjHYOugajnkrHmTgpPjAKY6v5yIiKn2T8aYOUQv7Z8AYFNEPB8RW93F1ZjBpnGwt7d/AvBdAFcDWI/JJ/+3xHH3RMSOiNjR+3CNMd3SdfunlFIrpXQ6pfQegO8B2MCOdfsnYwaDJmo8bf801eet4k4AvGG2MWYg6KX9010RsR5AArAXwBf7OTBWlVQpqKwap4KlHap0WVYIgKnTqu8YU+NVcQOm7Kq3DyxVVKXhsjcKStlV69COSvNkCrsqIpKjerM1V8UrWq1Wo89SsDcdqlgHe7Oj0oPZvfvAAw9QX3bfXHvttdS3PU7U2wCgt/ZPD5/tWGPM4OAMOmMKwcFuTCE42I0phIHdz86EDrVXmAlZLN1W+ebsfWdCmBKAclpFMZFRiS3svEqkZOugqrgyQZK1HXr66afp8Uw4XLduHfVduXJlo88HuCCoxEQmhLFrrtaLpZ+qveQsvVidd2xsrGYbGRmhvmzNVHXZ9mvZSaDzk92YQnCwG1MIDnZjCsHBbkwhONiNKYSBVeOZ6q2UbFaMQRVzYMquUuOZ6s0UY5WqytTa5cuXU9+cQgjMl6XFqnOwQhkAT0tla6uKTLDUWKWasyIeSslm51Xq9Kc//emajanxL774Ij2epT4fOHCA+u7evbtmm5iYoL7sHlMpsEylV2+icvof+sluTCE42I0pBAe7MYXgYDemEAZWoGNiEdvjDvDqo0qwYoJGjhDGhD/VpomJMmoObA+zGhcTKpXIyHzZ2gJcTFu2bFnNtnTpUno8G8PBgwepL0vDVXv9Weq0SlF+7LHHajZ2zfbu3UuPZ9dc7bNna8vaTwG8PRdbW4USOtV9zvCT3ZhCcLAbUwgOdmMKoUnByYsi4jcR8VzV/ukblX04IrZHxO7qq+vGGzPANBHo3gbw8ZTSyaqk9K8i4hEAfwPg8ZTSfRGxGcBmAF/t18BYQUElRrCMMFUkUBVxZDAxL0fAYWNQ2WerVq2q2ZRgxfajq3kxEUkVjGx6vMpkZCLU+vXrqS/LllMZdOy6P/roo9SXZbCx6zM8PEyPZ0IpswF8HdU9yq6ZEmCZ+KjqM7SvWSfB7qxP9jTJVEWA+dWfBOB2ANsq+zYAd5ztXMaY2aNpk4h5VRnpCQDbU0pPARip+sBN9YNr/h7BGDPjNAr2qvPLegCjADZEBM/gJ7j9kzGDQZYan1I6CuAJABsBtKa6wlRf6XYft38yZjBoosZfFhGXVn9fAOCTAP4A4CEAd1dudwN4cJrGaIzpA01k2csBbIuIeZj85nB/Sum/IuJJAPdHxBcA7AfwmX4ObO3atTXbzp28nVyvraKUmt4rTFVlqb3KV7U4Yvvnc94y5KRYMhVYrRfbc61UZKboq/OydOSNGzdSX1bhlr0VURVjWWqt8mX3mEpFVm8wGEylz3lToWjS/ul5TPZkb7cfAfCJxp9kjJlVnEFnTCE42I0pBAe7MYUwsPvZmUD3xz/+kfqytEVVkJCJNao4JRPNmG9O0T9VOJDtr1atk3LEHjY2Jeowe6d2Qk2OV5/F1lGl8TKRTxV2ZAUymWinBE12zdX1ZXvMlSDJ1kGdl9nV2ijhjuEnuzGF4GA3phAc7MYUgoPdmEJwsBtTCAOrxl911VU125VXXkl99+3bV7Op1MtFixbVbEytBbiC2mu6rVKn2ZsGNi8AuOaaa2o21dIpp61U0+OV4ty02Iey57wlUGNoerxKa2X0+kYCyFvHrIqxGWPzk92YQnCwG1MIDnZjCsHBbkwhDKxAx1r+fOQjH6G+zzzzTM2m2uWwdFUl1rB2Ruy8KmWRiTIqRZLtmf71r39NfTds2FCzqfRPNrYcIYzNt1eBT503x1fB1pcdr1KklZ3BKsaqeynHl10zdd+0X4tOqdt+shtTCA52YwrBwW5MIfTS/uneiBiLiGerP7dN/3CNMd3SS/snAPhOSumb0zc8Y0y/aFJwMgFg7Z+mFZZKyPqhKfurr75KfVlxg5wx5BQh6EVVBYDx8XHq22q1araRkRHqm5N6yQo3sKIJSh1n66V8mRKt1Hg2BpXizPrj9armK9WczTen0IUi55q1r1lPvd4A2f4JADZFxPMRsdVdXI0ZbHpp//RdAFcDWA9gHMC32LFu/2TMYNB1+6eUUqv6JvAegO8BqGd6wO2fjBkUum7/NNXnreJOALxdizFmIOil/dO/R8R6TIp1ewF8sZ8DY0IHqwwLAIcOHarZVJulnBTWplVjVYolE3CYCKbGparIsnZXam3YOVR6L5tvUxvA56tSa5ld+TKBbHh4mPqyNOuc9N6c9GJGTiqyumYs9Vn5to+301h7af/0ubMda4wZHJxBZ0whONiNKQQHuzGF4GA3phAGtngFU3yPHTtGfa+//vqaTaXLMrXy5MmTxJOnaTK1VqVT5ij/TY8HgCeeeKJm++hHP9r4vEqxZWo6WwPVd4zZlRKeUySCsWDBAmpvWuE2542EeoPC5qB6+TE1Xd3Px48fr9lUb7v2AiuqiAngJ7sxxeBgN6YQHOzGFIKD3ZhCGFiBjsFSIUuEiVMqPfjmm2+u2ZYvX059mZDVa5umnHZISjRjQtjQ0BD1bXo8qxwMcIFNjYudQ+2zZ8KZ8mXi8v79+6lv+zqqsQJ+shtTDA52YwrBwW5MITjYjSkEB7sxhRA5G/N7/rCImfswYwolpURzsv1kN6YQHOzGFIKD3ZhCcLAbUwgznS57GMC+6u9Lq3+fa3hec49zaW6r1X/MqBr/vg+O2HEuNo7wvOYe5/LczsQ/xhtTCA52YwphNoN9yyx+9nTiec09zuW5/T+z9ju7MWZm8Y/xxhTCjAd7RGyMiBcjYk9EbJ7pz+8nEbE1IiYiYucZtuGI2B4Ru6uvi2dzjN0QESsj4hcR8UJE7IqIL1X2OT23iLgoIn4TEc9V8/pGZZ/T82rKjAZ71Qn2XwF8CsAHAdwVER+cyTH0mR8A2Nhm2wzg8ZTSWgCPV/+ea5wC8JWU0joAHwbwD9V1mutzexvAx1NK1wNYD2BjRHwYc39ejZjpJ/sGAHtSSi+nlN4B8GMAt8/wGPpGSumXANoLht0OYFv1920A7pjJMfWDlNJ4Sum31d9PAHgBwArM8bmlSaY6gsyv/iTM8Xk1ZaaDfQWAA2f8+2BlO5cYSSmNA5NBA2DZLI+nJyJiDSZbdj+Fc2BuETEvIp4FMAFge0rpnJhXE2Y62Nk+W78OGFAiYgjATwB8OaVU70k0B0kpnU4prQcwCmBDRFw7y0OaMWY62A8CWHnGv0cBvDLDY5huWhFxOQBUX3mTrgEnIuZjMtB/mFL6aWU+J+YGACmlowCewKTmcs7MqxMzHexPA1gbEVdGxAUAPgvgoRkew3TzEIC7q7/fDeDBWRxLV8Rkd8PvA3ghpfTtM/5rTs8tIi6LiEurvy8A8EkAf8Acn1dTZjypJiJuA/DPAOYB2JpS+qcZHUAfiYgfAfgYJndNtQB8HcADAO4HsArAfgCfSSnxlrIDSkTcAuB/APwewFQXgq9h8vf2OTu3iLgOkwLcPEw+6O5PKf1jRCzBHJ5XU5xBZ0whOIPOmEJwsBtTCA52YwrBwW5MITjYjSkEB7sxheBgN6YQHOzGFML/AZPE6q6yKS1oAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "MAX_RESIZE = 0.2\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize(int(48 * (2 * MAX_RESIZE * np.random.random() + (1 - MAX_RESIZE)) + 0.5)),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(40, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0, 1),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.RandomCrop(40, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "data_train = datasets.ImageFolder(root=\"../data/train\", transform=transform_train)\n",
        "data_test = datasets.ImageFolder(root=\"../data/test\", transform=transform_test)\n",
        "\n",
        "print(f\"Training Examples: {len(data_train)}\")\n",
        "print(f\"Testing Examples: {len(data_test)}\")  # Dataset said we should have 3589 examples, yet we have x2 - duplicates??\n",
        "\n",
        "indx = 12345\n",
        "example = data_train[indx][0]\n",
        "label   = data_train[indx][1]\n",
        "\n",
        "print(f\"\\nLooking at example {indx} with label '{LABEL_ENCODING[label]}':\")\n",
        "print(example.shape)\n",
        "plt.imshow(np.squeeze(example), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaPaQ_Vz6SxX"
      },
      "source": [
        "# Part 4: Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "c1ENJvt86Scy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "num cpus: 12\n",
            "\n",
            "Test set: Average loss: 1.9446, Accuracy: 1024/7178 (14%)\n",
            "\n",
            "Wed Dec 15 17:38:35 2021 Train Epoch: 0 [0/28709 (0%)]\tLoss: 1.944619\n",
            "\n",
            "Test set: Average loss: 1.8123, Accuracy: 1774/7178 (25%)\n",
            "\n",
            "Wed Dec 15 17:39:07 2021 Train Epoch: 1 [0/28709 (0%)]\tLoss: 1.807840\n",
            "\n",
            "Test set: Average loss: 1.8690, Accuracy: 1598/7178 (22%)\n",
            "\n",
            "Wed Dec 15 17:39:40 2021 Train Epoch: 2 [0/28709 (0%)]\tLoss: 1.858780\n",
            "\n",
            "Test set: Average loss: 1.7799, Accuracy: 1835/7178 (26%)\n",
            "\n",
            "Wed Dec 15 17:40:12 2021 Train Epoch: 3 [0/28709 (0%)]\tLoss: 1.775099\n",
            "\n",
            "Test set: Average loss: 1.7702, Accuracy: 1946/7178 (27%)\n",
            "\n",
            "Wed Dec 15 17:40:44 2021 Train Epoch: 4 [0/28709 (0%)]\tLoss: 1.794204\n",
            "\n",
            "Test set: Average loss: 1.7776, Accuracy: 1885/7178 (26%)\n",
            "\n",
            "Wed Dec 15 17:41:17 2021 Train Epoch: 5 [0/28709 (0%)]\tLoss: 1.698081\n",
            "\n",
            "Test set: Average loss: 1.8026, Accuracy: 1876/7178 (26%)\n",
            "\n",
            "Wed Dec 15 17:41:49 2021 Train Epoch: 6 [0/28709 (0%)]\tLoss: 1.777859\n",
            "\n",
            "Test set: Average loss: 1.7724, Accuracy: 1916/7178 (27%)\n",
            "\n",
            "Wed Dec 15 17:42:22 2021 Train Epoch: 7 [0/28709 (0%)]\tLoss: 1.740306\n",
            "\n",
            "Test set: Average loss: 1.7369, Accuracy: 2143/7178 (30%)\n",
            "\n",
            "Wed Dec 15 17:42:54 2021 Train Epoch: 8 [0/28709 (0%)]\tLoss: 1.610271\n",
            "\n",
            "Test set: Average loss: 1.7347, Accuracy: 2187/7178 (30%)\n",
            "\n",
            "Wed Dec 15 17:43:27 2021 Train Epoch: 9 [0/28709 (0%)]\tLoss: 1.587437\n",
            "\n",
            "Test set: Average loss: 1.7216, Accuracy: 2176/7178 (30%)\n",
            "\n",
            "Wed Dec 15 17:43:59 2021 Train Epoch: 10 [0/28709 (0%)]\tLoss: 1.627036\n",
            "\n",
            "Test set: Average loss: 1.6622, Accuracy: 2407/7178 (34%)\n",
            "\n",
            "Wed Dec 15 17:44:32 2021 Train Epoch: 11 [0/28709 (0%)]\tLoss: 1.459717\n",
            "\n",
            "Test set: Average loss: 1.6897, Accuracy: 2472/7178 (34%)\n",
            "\n",
            "Wed Dec 15 17:45:04 2021 Train Epoch: 12 [0/28709 (0%)]\tLoss: 1.582025\n",
            "\n",
            "Test set: Average loss: 1.6266, Accuracy: 2556/7178 (36%)\n",
            "\n",
            "Wed Dec 15 17:45:37 2021 Train Epoch: 13 [0/28709 (0%)]\tLoss: 1.481728\n",
            "\n",
            "Test set: Average loss: 1.6151, Accuracy: 2643/7178 (37%)\n",
            "\n",
            "Wed Dec 15 17:46:09 2021 Train Epoch: 14 [0/28709 (0%)]\tLoss: 1.472935\n",
            "\n",
            "Test set: Average loss: 1.5499, Accuracy: 2809/7178 (39%)\n",
            "\n",
            "Wed Dec 15 17:46:42 2021 Train Epoch: 15 [0/28709 (0%)]\tLoss: 1.408550\n",
            "\n",
            "Test set: Average loss: 1.5622, Accuracy: 2750/7178 (38%)\n",
            "\n",
            "Wed Dec 15 17:47:14 2021 Train Epoch: 16 [0/28709 (0%)]\tLoss: 1.478886\n",
            "\n",
            "Test set: Average loss: 1.5090, Accuracy: 2949/7178 (41%)\n",
            "\n",
            "Wed Dec 15 17:47:47 2021 Train Epoch: 17 [0/28709 (0%)]\tLoss: 1.264848\n",
            "\n",
            "Test set: Average loss: 1.5501, Accuracy: 2894/7178 (40%)\n",
            "\n",
            "Wed Dec 15 17:48:19 2021 Train Epoch: 18 [0/28709 (0%)]\tLoss: 1.440443\n",
            "\n",
            "Test set: Average loss: 1.6929, Accuracy: 2416/7178 (34%)\n",
            "\n",
            "Wed Dec 15 17:48:52 2021 Train Epoch: 19 [0/28709 (0%)]\tLoss: 1.521570\n",
            "\n",
            "Test set: Average loss: 1.5697, Accuracy: 2857/7178 (40%)\n",
            "\n",
            "Wed Dec 15 17:49:24 2021 Train Epoch: 20 [0/28709 (0%)]\tLoss: 1.368121\n",
            "\n",
            "Test set: Average loss: 1.4522, Accuracy: 3130/7178 (44%)\n",
            "\n",
            "Wed Dec 15 17:49:57 2021 Train Epoch: 21 [0/28709 (0%)]\tLoss: 1.262293\n",
            "\n",
            "Test set: Average loss: 1.4951, Accuracy: 3136/7178 (44%)\n",
            "\n",
            "Wed Dec 15 17:50:29 2021 Train Epoch: 22 [0/28709 (0%)]\tLoss: 1.323493\n",
            "\n",
            "Test set: Average loss: 1.5082, Accuracy: 3049/7178 (42%)\n",
            "\n",
            "Wed Dec 15 17:51:02 2021 Train Epoch: 23 [0/28709 (0%)]\tLoss: 1.372719\n",
            "\n",
            "Test set: Average loss: 1.4312, Accuracy: 3237/7178 (45%)\n",
            "\n",
            "Wed Dec 15 17:51:34 2021 Train Epoch: 24 [0/28709 (0%)]\tLoss: 1.147088\n",
            "\n",
            "Test set: Average loss: 1.4035, Accuracy: 3297/7178 (46%)\n",
            "\n",
            "Wed Dec 15 17:52:06 2021 Train Epoch: 25 [0/28709 (0%)]\tLoss: 1.239058\n",
            "\n",
            "Test set: Average loss: 1.3739, Accuracy: 3387/7178 (47%)\n",
            "\n",
            "Wed Dec 15 17:52:39 2021 Train Epoch: 26 [0/28709 (0%)]\tLoss: 1.145163\n",
            "\n",
            "Test set: Average loss: 1.4409, Accuracy: 3207/7178 (45%)\n",
            "\n",
            "Wed Dec 15 17:53:11 2021 Train Epoch: 27 [0/28709 (0%)]\tLoss: 1.218294\n",
            "\n",
            "Test set: Average loss: 1.3794, Accuracy: 3379/7178 (47%)\n",
            "\n",
            "Wed Dec 15 17:53:44 2021 Train Epoch: 28 [0/28709 (0%)]\tLoss: 1.195065\n",
            "\n",
            "Test set: Average loss: 1.3742, Accuracy: 3464/7178 (48%)\n",
            "\n",
            "Wed Dec 15 17:54:16 2021 Train Epoch: 29 [0/28709 (0%)]\tLoss: 1.110653\n",
            "\n",
            "Test set: Average loss: 1.4054, Accuracy: 3455/7178 (48%)\n",
            "\n",
            "Wed Dec 15 17:54:49 2021 Train Epoch: 30 [0/28709 (0%)]\tLoss: 1.145446\n",
            "\n",
            "Test set: Average loss: 1.4162, Accuracy: 3300/7178 (46%)\n",
            "\n",
            "Wed Dec 15 17:55:21 2021 Train Epoch: 31 [0/28709 (0%)]\tLoss: 1.206496\n",
            "\n",
            "Test set: Average loss: 1.3946, Accuracy: 3367/7178 (47%)\n",
            "\n",
            "Wed Dec 15 17:55:52 2021 Train Epoch: 32 [0/28709 (0%)]\tLoss: 1.183796\n",
            "\n",
            "Test set: Average loss: 1.4053, Accuracy: 3326/7178 (46%)\n",
            "\n",
            "Wed Dec 15 17:56:24 2021 Train Epoch: 33 [0/28709 (0%)]\tLoss: 1.098322\n",
            "\n",
            "Test set: Average loss: 1.4453, Accuracy: 3399/7178 (47%)\n",
            "\n",
            "Wed Dec 15 17:56:56 2021 Train Epoch: 34 [0/28709 (0%)]\tLoss: 1.142133\n",
            "\n",
            "Test set: Average loss: 1.6199, Accuracy: 3226/7178 (45%)\n",
            "\n",
            "Wed Dec 15 17:57:27 2021 Train Epoch: 35 [0/28709 (0%)]\tLoss: 1.245360\n",
            "\n",
            "Test set: Average loss: 1.3739, Accuracy: 3411/7178 (48%)\n",
            "\n",
            "Wed Dec 15 17:57:59 2021 Train Epoch: 36 [0/28709 (0%)]\tLoss: 1.138667\n",
            "\n",
            "Test set: Average loss: 1.3591, Accuracy: 3521/7178 (49%)\n",
            "\n",
            "Wed Dec 15 17:58:30 2021 Train Epoch: 37 [0/28709 (0%)]\tLoss: 1.098256\n",
            "\n",
            "Test set: Average loss: 1.4859, Accuracy: 3267/7178 (46%)\n",
            "\n",
            "Wed Dec 15 17:59:02 2021 Train Epoch: 38 [0/28709 (0%)]\tLoss: 1.099733\n",
            "\n",
            "Test set: Average loss: 1.3462, Accuracy: 3585/7178 (50%)\n",
            "\n",
            "Wed Dec 15 17:59:34 2021 Train Epoch: 39 [0/28709 (0%)]\tLoss: 1.138253\n",
            "\n",
            "Test set: Average loss: 1.4007, Accuracy: 3450/7178 (48%)\n",
            "\n",
            "Wed Dec 15 18:00:06 2021 Train Epoch: 40 [0/28709 (0%)]\tLoss: 1.092093\n",
            "\n",
            "Test set: Average loss: 1.3080, Accuracy: 3628/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:00:39 2021 Train Epoch: 41 [0/28709 (0%)]\tLoss: 1.042516\n",
            "\n",
            "Test set: Average loss: 1.3145, Accuracy: 3628/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:01:12 2021 Train Epoch: 42 [0/28709 (0%)]\tLoss: 1.053067\n",
            "\n",
            "Test set: Average loss: 1.3079, Accuracy: 3646/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:01:44 2021 Train Epoch: 43 [0/28709 (0%)]\tLoss: 1.089187\n",
            "\n",
            "Test set: Average loss: 1.3786, Accuracy: 3640/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:02:17 2021 Train Epoch: 44 [0/28709 (0%)]\tLoss: 1.042508\n",
            "\n",
            "Test set: Average loss: 1.4077, Accuracy: 3488/7178 (49%)\n",
            "\n",
            "Wed Dec 15 18:02:50 2021 Train Epoch: 45 [0/28709 (0%)]\tLoss: 1.143302\n",
            "\n",
            "Test set: Average loss: 1.3879, Accuracy: 3540/7178 (49%)\n",
            "\n",
            "Wed Dec 15 18:03:23 2021 Train Epoch: 46 [0/28709 (0%)]\tLoss: 1.179584\n",
            "\n",
            "Test set: Average loss: 1.4694, Accuracy: 3319/7178 (46%)\n",
            "\n",
            "Wed Dec 15 18:03:56 2021 Train Epoch: 47 [0/28709 (0%)]\tLoss: 1.188475\n",
            "\n",
            "Test set: Average loss: 1.3159, Accuracy: 3642/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:04:28 2021 Train Epoch: 48 [0/28709 (0%)]\tLoss: 1.000199\n",
            "\n",
            "Test set: Average loss: 1.3218, Accuracy: 3672/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:05:01 2021 Train Epoch: 49 [0/28709 (0%)]\tLoss: 1.054517\n",
            "\n",
            "Test set: Average loss: 1.3184, Accuracy: 3713/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:05:33 2021 Train Epoch: 50 [0/28709 (0%)]\tLoss: 1.131781\n",
            "\n",
            "Test set: Average loss: 1.3756, Accuracy: 3596/7178 (50%)\n",
            "\n",
            "Wed Dec 15 18:06:06 2021 Train Epoch: 51 [0/28709 (0%)]\tLoss: 0.959956\n",
            "\n",
            "Test set: Average loss: 1.2807, Accuracy: 3749/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:06:38 2021 Train Epoch: 52 [0/28709 (0%)]\tLoss: 1.005245\n",
            "\n",
            "Test set: Average loss: 1.2831, Accuracy: 3749/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:07:11 2021 Train Epoch: 53 [0/28709 (0%)]\tLoss: 1.070816\n",
            "\n",
            "Test set: Average loss: 1.3203, Accuracy: 3665/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:07:43 2021 Train Epoch: 54 [0/28709 (0%)]\tLoss: 1.024443\n",
            "\n",
            "Test set: Average loss: 1.2936, Accuracy: 3750/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:08:16 2021 Train Epoch: 55 [0/28709 (0%)]\tLoss: 0.956613\n",
            "\n",
            "Test set: Average loss: 1.3088, Accuracy: 3797/7178 (53%)\n",
            "\n",
            "Wed Dec 15 18:08:48 2021 Train Epoch: 56 [0/28709 (0%)]\tLoss: 1.060912\n",
            "\n",
            "Test set: Average loss: 1.3235, Accuracy: 3733/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:09:20 2021 Train Epoch: 57 [0/28709 (0%)]\tLoss: 1.054958\n",
            "\n",
            "Test set: Average loss: 1.3088, Accuracy: 3747/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:09:53 2021 Train Epoch: 58 [0/28709 (0%)]\tLoss: 0.957771\n",
            "\n",
            "Test set: Average loss: 1.3173, Accuracy: 3756/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:10:25 2021 Train Epoch: 59 [0/28709 (0%)]\tLoss: 0.958064\n",
            "\n",
            "Test set: Average loss: 1.3753, Accuracy: 3596/7178 (50%)\n",
            "\n",
            "Wed Dec 15 18:10:58 2021 Train Epoch: 60 [0/28709 (0%)]\tLoss: 1.018301\n",
            "\n",
            "Test set: Average loss: 1.3527, Accuracy: 3588/7178 (50%)\n",
            "\n",
            "Wed Dec 15 18:11:30 2021 Train Epoch: 61 [0/28709 (0%)]\tLoss: 0.934068\n",
            "\n",
            "Test set: Average loss: 1.3397, Accuracy: 3649/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:12:02 2021 Train Epoch: 62 [0/28709 (0%)]\tLoss: 1.033701\n",
            "\n",
            "Test set: Average loss: 1.2959, Accuracy: 3807/7178 (53%)\n",
            "\n",
            "Wed Dec 15 18:12:35 2021 Train Epoch: 63 [0/28709 (0%)]\tLoss: 0.954167\n",
            "\n",
            "Test set: Average loss: 1.4655, Accuracy: 3490/7178 (49%)\n",
            "\n",
            "Wed Dec 15 18:13:07 2021 Train Epoch: 64 [0/28709 (0%)]\tLoss: 1.006187\n",
            "\n",
            "Test set: Average loss: 1.3337, Accuracy: 3636/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:13:40 2021 Train Epoch: 65 [0/28709 (0%)]\tLoss: 0.908516\n",
            "\n",
            "Test set: Average loss: 1.3255, Accuracy: 3711/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:14:12 2021 Train Epoch: 66 [0/28709 (0%)]\tLoss: 0.914555\n",
            "\n",
            "Test set: Average loss: 1.3822, Accuracy: 3625/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:14:44 2021 Train Epoch: 67 [0/28709 (0%)]\tLoss: 0.909406\n",
            "\n",
            "Test set: Average loss: 1.3024, Accuracy: 3791/7178 (53%)\n",
            "\n",
            "Wed Dec 15 18:15:16 2021 Train Epoch: 68 [0/28709 (0%)]\tLoss: 0.939881\n",
            "\n",
            "Test set: Average loss: 1.3671, Accuracy: 3703/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:15:48 2021 Train Epoch: 69 [0/28709 (0%)]\tLoss: 0.938394\n",
            "\n",
            "Test set: Average loss: 1.3918, Accuracy: 3660/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:16:19 2021 Train Epoch: 70 [0/28709 (0%)]\tLoss: 0.965609\n",
            "\n",
            "Test set: Average loss: 1.3087, Accuracy: 3804/7178 (53%)\n",
            "\n",
            "Wed Dec 15 18:16:51 2021 Train Epoch: 71 [0/28709 (0%)]\tLoss: 0.803664\n",
            "\n",
            "Test set: Average loss: 1.2638, Accuracy: 3915/7178 (55%)\n",
            "\n",
            "Wed Dec 15 18:17:22 2021 Train Epoch: 72 [0/28709 (0%)]\tLoss: 0.911959\n",
            "\n",
            "Test set: Average loss: 1.4238, Accuracy: 3613/7178 (50%)\n",
            "\n",
            "Wed Dec 15 18:17:54 2021 Train Epoch: 73 [0/28709 (0%)]\tLoss: 0.971272\n",
            "\n",
            "Test set: Average loss: 1.4917, Accuracy: 3494/7178 (49%)\n",
            "\n",
            "Wed Dec 15 18:18:26 2021 Train Epoch: 74 [0/28709 (0%)]\tLoss: 1.042337\n",
            "\n",
            "Test set: Average loss: 1.3440, Accuracy: 3858/7178 (54%)\n",
            "\n",
            "Wed Dec 15 18:18:57 2021 Train Epoch: 75 [0/28709 (0%)]\tLoss: 0.921872\n",
            "\n",
            "Test set: Average loss: 1.3635, Accuracy: 3752/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:19:29 2021 Train Epoch: 76 [0/28709 (0%)]\tLoss: 0.835067\n",
            "\n",
            "Test set: Average loss: 1.3813, Accuracy: 3608/7178 (50%)\n",
            "\n",
            "Wed Dec 15 18:20:01 2021 Train Epoch: 77 [0/28709 (0%)]\tLoss: 0.857203\n",
            "\n",
            "Test set: Average loss: 1.3467, Accuracy: 3793/7178 (53%)\n",
            "\n",
            "Wed Dec 15 18:20:32 2021 Train Epoch: 78 [0/28709 (0%)]\tLoss: 0.845674\n",
            "\n",
            "Test set: Average loss: 1.3579, Accuracy: 3761/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:21:04 2021 Train Epoch: 79 [0/28709 (0%)]\tLoss: 0.975329\n",
            "\n",
            "Test set: Average loss: 1.2941, Accuracy: 3909/7178 (54%)\n",
            "\n",
            "Wed Dec 15 18:21:35 2021 Train Epoch: 80 [0/28709 (0%)]\tLoss: 0.822980\n",
            "\n",
            "Test set: Average loss: 1.3407, Accuracy: 3619/7178 (50%)\n",
            "\n",
            "Wed Dec 15 18:22:07 2021 Train Epoch: 81 [0/28709 (0%)]\tLoss: 0.929387\n",
            "\n",
            "Test set: Average loss: 1.4082, Accuracy: 3768/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:22:39 2021 Train Epoch: 82 [0/28709 (0%)]\tLoss: 0.906775\n",
            "\n",
            "Test set: Average loss: 1.6117, Accuracy: 3372/7178 (47%)\n",
            "\n",
            "Wed Dec 15 18:23:10 2021 Train Epoch: 83 [0/28709 (0%)]\tLoss: 0.951494\n",
            "\n",
            "Test set: Average loss: 1.2985, Accuracy: 3794/7178 (53%)\n",
            "\n",
            "Wed Dec 15 18:23:42 2021 Train Epoch: 84 [0/28709 (0%)]\tLoss: 0.858307\n",
            "\n",
            "Test set: Average loss: 1.3743, Accuracy: 3834/7178 (53%)\n",
            "\n",
            "Wed Dec 15 18:24:13 2021 Train Epoch: 85 [0/28709 (0%)]\tLoss: 0.988333\n",
            "\n",
            "Test set: Average loss: 1.4893, Accuracy: 3653/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:24:45 2021 Train Epoch: 86 [0/28709 (0%)]\tLoss: 0.900032\n",
            "\n",
            "Test set: Average loss: 1.3904, Accuracy: 3637/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:25:17 2021 Train Epoch: 87 [0/28709 (0%)]\tLoss: 0.939078\n",
            "\n",
            "Test set: Average loss: 1.2711, Accuracy: 3843/7178 (54%)\n",
            "\n",
            "Wed Dec 15 18:25:48 2021 Train Epoch: 88 [0/28709 (0%)]\tLoss: 0.812014\n",
            "\n",
            "Test set: Average loss: 1.3613, Accuracy: 3715/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:26:20 2021 Train Epoch: 89 [0/28709 (0%)]\tLoss: 0.868186\n",
            "\n",
            "Test set: Average loss: 1.3653, Accuracy: 3725/7178 (52%)\n",
            "\n",
            "Wed Dec 15 18:26:51 2021 Train Epoch: 90 [0/28709 (0%)]\tLoss: 0.819332\n",
            "\n",
            "Test set: Average loss: 1.4644, Accuracy: 3639/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:27:23 2021 Train Epoch: 91 [0/28709 (0%)]\tLoss: 0.898763\n",
            "\n",
            "Test set: Average loss: 1.4453, Accuracy: 3690/7178 (51%)\n",
            "\n",
            "Wed Dec 15 18:27:55 2021 Train Epoch: 92 [0/28709 (0%)]\tLoss: 0.850485\n",
            "Interrupted\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Play around with these constants, you may find a better setting.\n",
        "BATCH_SIZE = 512\n",
        "TEST_BATCH_SIZE = 10\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.08\n",
        "MOMENTUM = 0.9\n",
        "USE_CUDA = True\n",
        "PRINT_INTERVAL = 100\n",
        "WEIGHT_DECAY = 0.001\n",
        "\n",
        "# Now the actual training code\n",
        "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "print('num cpus:', multiprocessing.cpu_count())\n",
        "\n",
        "kwargs = {'num_workers': multiprocessing.cpu_count(),\n",
        "          'pin_memory': True} if use_cuda else {}\n",
        "kwargs = {}\n",
        "\n",
        "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=TEST_BATCH_SIZE,\n",
        "                                          shuffle=True, **kwargs)\n",
        "\n",
        "model = EmojifyNet().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "start_epoch = 0 # model.load_last_model(LOG_PATH)\n",
        "\n",
        "train_losses, test_losses, test_accuracies = [], [], [] # pt_util.read_log(LOG_PATH + 'log.pkl', ([], [], []))\n",
        "test_loss, test_accuracy = test(model, device, test_loader)\n",
        "\n",
        "test_losses.append(test_loss)\n",
        "test_accuracies.append(test_accuracy)\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, EPOCHS + 1):\n",
        "        train_loss = train(model, device, train_loader, optimizer, epoch, PRINT_INTERVAL)\n",
        "        test_loss, test_accuracy = test(model, device, test_loader)\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "        # pt_util.write_log(LOG_PATH + 'log.pkl', (train_losses, test_losses, test_accuracies))\n",
        "        # model.save_best_model(test_accuracy, LOG_PATH + '%03d.pt' % epoch)\n",
        "\n",
        "\n",
        "except KeyboardInterrupt as ke:\n",
        "    print('Interrupted')\n",
        "except:\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    # model.save_model(LOG_PATH + '%03d.pt' % epoch, 0)\n",
        "    # ep, val = zip(*train_losses)\n",
        "    # pt_util.plot(ep, val, 'Train loss', 'Epoch', 'Error')\n",
        "    # ep, val = zip(*test_losses)\n",
        "    # pt_util.plot(ep, val, 'Test loss', 'Epoch', 'Error')\n",
        "    # ep, val = zip(test_accuracies)\n",
        "    # pt_util.plot(ep, val, 'Test accuracy', 'Epoch', 'Error')\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final train loss: 0.8953868140254104\n",
            "Final test loss:  1.2624089059207924\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"\n",
        " lr: \n",
        "    0.01 => 25% test accuracy (constant)\n",
        "    0.05 => 25% test accuracy (constant)\n",
        "    0.1  => 33% test accuracy\n",
        "    0.2  => 46% test accuracy\n",
        "    0.3  => --- test accuracy\n",
        "    0.5  => --- test accuracy\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "before:\n",
        "    train-loss: 0.6977\n",
        "    test-loss:  2.4902\n",
        "\n",
        "after:\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Final train loss: {train_losses[-1]}\")\n",
        "print(f\"Final test loss:  {test_losses[-1]}\")\n",
        "\n",
        "x_axis = np.arange(0, EPOCHS + 2)\n",
        "plt.plot(x_axis, test_accuracies)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('test accuracy')\n",
        "model.save_model('best-model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected 4-dimensional input for 4-dimensional weight [32, 1, 3, 3], but got 3-dimensional input of size [1, 40, 40] instead",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-181-ea40ca52a64a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-167-930ae0f631b0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\446-hw\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 420\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 1, 3, 3], but got 3-dimensional input of size [1, 40, 40] instead"
          ]
        }
      ],
      "source": [
        "x = model.load_model('best-model')\n",
        "idx = 0\n",
        "e = data_test[idx][0]\n",
        "label = data_test[idx][1]\n",
        "output = model(e)\n",
        "output.max(1)[1]\n",
        "print(label)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "train-model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
